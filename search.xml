<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>JAVA八股 数据库</title>
      <link href="/2025/11/21/JAVA%E5%85%AB%E8%82%A1-%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
      <url>/2025/11/21/JAVA%E5%85%AB%E8%82%A1-%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL篇"><a href="#MySQL篇" class="headerlink" title="MySQL篇"></a>MySQL篇</h1><h2 id="如何定位慢查询"><a href="#如何定位慢查询" class="headerlink" title="如何定位慢查询"></a>如何定位慢查询</h2><p>出现的表象：页面加载太慢，接口压测响应时间超过1s</p><p>出现的本质：</p><ol><li>查表时出现聚合查询</li><li>多表查询</li><li>表数据量过大的查询</li><li>深度分页查询</li></ol><p>解决方案：</p><ol><li><p>开源工具：Arthas，Prometheus</p></li><li><p>MySQL自带的工具：慢日志查询</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slow_query_log = 1 # 开启慢日志查询</span><br><span class="line">long_query_time = 2 # 设置慢日志查询时间阈值为2s</span><br></pre></td></tr></table></figure><p>配置完成之后，查询启动MySQL服务器进行测试，在&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;localhost-slow.log中查看结果</p><p>注意： 一般只在测试阶段才会做，因为正常使用的时候打开慢日志查询会降低性能。</p></li></ol><h2 id="这个SQL语句执行很慢，如何分析？"><a href="#这个SQL语句执行很慢，如何分析？" class="headerlink" title="这个SQL语句执行很慢，如何分析？"></a>这个SQL语句执行很慢，如何分析？</h2><p>通过SQL执行计划，找到慢的原因。</p><p>科研采用EXPLAIN或者DESC命令获得MySQL如何执行SELECT语句的信息<img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165136.png" alt="image-20251120113657376"><br>possible_keys :当前sql可能会使用到的索引</p><p>key： 当前sql实际命中的索引</p><p>key_len: 索引占用的大小 ，结合key字段可以判断是否命中了索引（索引本身是否失效）</p><p>Extra: 额外优化建议：</p><p>​Using where；Using Index： 查找使用了索引，但是需要的数据都在索引列中能找到，不需要回表查询数据</p><p>​Using index condition： 查找使用了索引，但是需要回表查询数据(通过添加索引或者修改返回字段修复)</p><p>type： 表示这条sql的连接类型：性能好到差：Null，system，const，eq_ref，ref，range，index，all（开发中最低到range）</p><p><img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165404.png" alt="image-20251120122924221"></p><h2 id="什么是索引？"><a href="#什么是索引？" class="headerlink" title="什么是索引？"></a>什么是索引？</h2><p>索引是帮助MySQL高效获取数据的数据结构（有序）。除了数据之外，数据库还维护着特定的数据交换（B+树），这些结构指向存储的数据，使用高级查找算法高效获取数据。</p><p>索引的底层： B+树。MySQL的InnoDB采用B+树的数据结构来存储索引</p><p>B+树与B树相比，优势在于：</p><ol><li>读写磁盘代价更低：B+树内部节点没有具体的内容指针，只记录儿子地址，故IO读取时可以读取更多关键字</li><li>更高效：查询路径都相同（都必须走到叶子才知道结果）。</li><li>更有利于数据库扫描：叶子之间相连（方便区间查询），支持顺序查询和根查询。</li></ol><h2 id="聚簇索引与非聚簇索引"><a href="#聚簇索引与非聚簇索引" class="headerlink" title="聚簇索引与非聚簇索引"></a>聚簇索引与非聚簇索引</h2><p><strong>聚簇索引（聚集索引）</strong>：数据和索引放到一起，B+树的叶子节点保存了整行数据，有且只有一个</p><p><strong>聚簇索引选取规则</strong>：存在主键，主键为聚簇索引；无主键唯一索引为聚簇索引，都无，InnDB自动生成rowid作为隐藏索引</p><p><strong>非聚簇索引</strong>：数据与索引分开存储，B+树的叶子节点保存了对应的主键。可以有多个</p><p><img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165428.png" alt="image-20251120195931408"></p><p>图中Id为主键，为name添加索引后，形成的非聚簇索引B+树。</p><p>回表查询： Eg：select * from user where name &#x3D; ‘Arm’;</p><p>由于name添加了索引，所以会走下面的B+树，但查询到的是主键地址，而结果却要*，这样查到了主键地址也没用，还得再走一遍聚簇索引。</p><p>回表操作就是：通过二级查询找到了对应的主键值，再到聚簇索引中查找了整行数据，这个过程就称为回表。</p><h2 id="覆盖索引，超大分页优化"><a href="#覆盖索引，超大分页优化" class="headerlink" title="覆盖索引，超大分页优化"></a>覆盖索引，超大分页优化</h2><p><strong>覆盖索引</strong>： 查询使用了索引，返回的列必须再索引中全部找到。 可以说索引成功了（不用回表查询）就是覆盖索引，而失败了（没有在结果中找到全部的结果）就要回表查询。</p><p>启示：尽量不要使用select *，如果返回的列中没有创建索引，就可能触发回表查询。</p><p><strong>超大分页优化</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM tb_sku ORDER BY id LIMIT 9000000, 10;</span><br></pre></td></tr></table></figure><p><strong>需要先扫描前 9000000+10 条数据，然后丢弃前 9000000 条</strong> （关键点在这里，需要优化）<br>即便 id 有索引，也需要回表 9000010 次（每次都要读取磁盘数据）<br>当 offset 极大时，性能急剧下降（本质是 O(n) 复杂度）</p><p><strong>优化分页</strong>：让id作主键或者唯一索引</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT t.* </span><br><span class="line">FROM tb_sku t, </span><br><span class="line">     (SELECT id FROM tb_sku ORDER BY id LIMIT 9000000, 10) a </span><br><span class="line">WHERE t.id = a.id;</span><br></pre></td></tr></table></figure><p>只要扫描索引树的9000010 个节点（不需要回表查询），而是是O(logn),最后只要与主查询关联，再额外查10个就可以结束。</p><h2 id="索引创建的原则"><a href="#索引创建的原则" class="headerlink" title="索引创建的原则"></a>索引创建的原则</h2><p>常见索引： 主键索引，唯一索引，<strong>复合索引</strong></p><p>原则： </p><ol><li>数据量大且查询比较频繁的表建立索引</li><li>字段：常作为where，order by,group by操作的字段，应该建立索引</li><li>区分度搞的列，尽量建立唯一索引，区分度越高，使用索引效率就高</li><li>字段为字符串，字段很长则建立前缀索引</li><li>鼓励使用联合索引，而不是单列索引。联合索引很多时候可以覆盖索引，不用回表。提高查询效率</li><li>索引并不是越多越高，维护索引也有额外开销</li><li>索引列不存NULL，则创建表时使用NOT NULL约束</li></ol><h2 id="索引失效的情况"><a href="#索引失效的情况" class="headerlink" title="索引失效的情况"></a>索引失效的情况</h2><p><img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165454.png" alt="image-20251121103641051"></p><p>通过explain，结合key和key_len字段可以判断索引是否失效</p><ol><li><p>违反最左前缀法则：</p><p>索引多列的时候，要从查询条件要从最左端开始，并且不能跳过索引中的列。<img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165519.png" alt="image-20251121103841643"></p><p>失败情况：<img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165543.png" alt="image-20251121103931351"></p><p>2.范围查询时，右边的列不能使用索引。<img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165600.png" alt="image-20251121104015802"></p><p>此时status还是走索引，但是address没有命中索引了</p><ol start="3"><li>不要在索引列上进行运算操作，否则索引失效</li><li>字符串不加引号，造成索引失效。</li><li>like关键字匹配的%开头的模糊匹配。 like “%abc%”,like “%abc”,like “abc%”只有最后一个生效</li></ol></li></ol><h2 id="sql优化经验"><a href="#sql优化经验" class="headerlink" title="sql优化经验"></a>sql优化经验</h2><ol><li>表的设计优化</li><li>索引优化：参考索引创建原则与索引失效情况</li><li>SQL语句优化：<ol><li>SELECT语句，务必指明具体字段，不要使用*</li><li>SQL要避免索引失效的情况</li><li>尽量用union all 去代替 union，union会多一次过滤，对获取的结果进行排序操作。union all只是合并查询结果，并不会进行去重和排序操作，在没有去重的前提下，使用union all的执行效率要比union高</li><li>避免在where子句中对字段进行表达式操作</li><li>能用innerjoin就不用left join&#x2F;right join，必须使用时，以小表为驱动。内连接会对两个表进行优化，优先把小表放在外面，大表放在里面。而外连接不会。</li></ol></li><li>写入操作很多时，采用主从复制，读写分离的架构：主DB复制写，从DB复制读，主DB会根据规则把数据同步到从DB中。</li></ol><h2 id="事务的特性"><a href="#事务的特性" class="headerlink" title="事务的特性"></a>事务的特性</h2><p>ACID.</p><p>A:原子性，事务是最小的操作单元，要么全部成功，要么全部失败。 </p><p>C:一致性，事务完成时，必须使所有数据都保持一致的状态。</p><p>I:隔离性，依托DB的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行。</p><p>D:持久性，事务一旦提交或回滚，它对数据库的改变就是永久的。</p><h2 id="并发事务问题"><a href="#并发事务问题" class="headerlink" title="并发事务问题"></a>并发事务问题</h2><p>脏读：一个事务读到另外一个事务还没提交的数据。</p><p>不可重复读：一个事务先后读取同一条记录，但两次读取的数据不同。</p><p>幻读：一个事务按照条件查询数据时，没有对应的数据行，但是插入数据时，又发现这行数据已经存在。</p><p>** 丢失修改：两个事务同时对一个数据继续操作，比如A&#x3D;20，但事务A,B同时对A-1，最后A&#x3D;19。称为丢失修改。</p><p>不可重复读与幻读的区别：</p><ul><li>不可重复读的重点是内容修改或者记录减少比如多次读取一条记录发现其中某些记录的值被修改；</li><li>幻读的重点在于记录新增比如多次执行同一条查询语句（DQL）时，发现查到的记录增加了。</li></ul><p>​幻读其实可以看作是不可重复读的一种特殊情况，单独把幻读区分出来的原因主要是解决幻读和不可重复读的方案不一样。</p><p>解决方案：对事物进行隔离：从上到下隔离级别依次提高，但是性能越来越低。<img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165621.png" alt="image-20251121111312995"></p><h2 id="undo-log与redo-log区别"><a href="#undo-log与redo-log区别" class="headerlink" title="undo log与redo log区别"></a>undo log与redo log区别</h2><p>缓冲池：主存中的一个区域，可以缓存磁盘上经常操作的真实数据。执行CRUD时，先操作缓冲池中的数据，随后再将池中数据写入磁盘。</p><p>数据页：InnoDB存储引擎磁盘管理的最小单元。</p><p>redo log：</p><p>​内存中加入了Redolog buffer，主要记录数据页的变化并上传到磁盘中的redolog中。磁盘中也加入了ib_logfile0&#x2F;1(redolog磁盘数据)，用于接收内存中的redolog buffer中的数据。当内存中的脏页同步失败时，就用该数据完成更新。日志文件中的读写操作都是顺序的磁盘IO。当脏页正常写入磁盘时，redolog磁盘数据就没有用了，会循环使用这篇磁盘空间，定时清理。</p><p>undo log：</p><p>​回滚日志，用于记录数据被修改前的信息。作用包括：提供回滚，MVCC。undo log主要记录逻辑日志。</p><p>​当delete一条数据时，undo log会对应记录一条insert记录，反之亦然</p><p>​当update一条记录时，它会记录一条对应相反的update数据，当执行rollback时，可以通过undolog进行回滚。</p><p>区别： redo log是记录数据页的物理变化，当发生宕机时可以同步数据。undo log记录逻辑日志，回滚时提供逆操作的数据。redolog保证了持久性，而undolog保证了原子性和一致性</p><h2 id="什么是MVCC"><a href="#什么是MVCC" class="headerlink" title="什么是MVCC"></a>什么是MVCC</h2><p>MVCC：多版本并发控制。维护一个数据多个版本，使得读写没有冲突。</p><p><img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165648.png" alt="image-20251121141943744"></p><p>MVCC主要依赖于：隐藏字段，undolog，readview<img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165705.png" alt="image-20251121142224387"></p><p>undo log：</p><p>​insert时，产生的undolog只在回滚时需要，当在事务提交后，可被立即删除。</p><p>​update和delete时，产生的undo log日志不仅在回滚时需要，mvcc版本控制也需要，不会立即被删除。</p><p>undo log版本链：</p><p>​<img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165718.png" alt="image-20251121142658432"></p><p>不同的事务或者相同的事务对同一记录进行修改，会导致该记录的undolog生成一条记录版本的链表，头部是最新的旧纪录，尾部是最早的旧纪录</p><p>readview（读视图）：</p><p>​是快照读SQL执行时MVCC提供数据的依据，记录并维护系统当前活跃的事务。</p><p>​当前读：读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录。</p><p>​快照读：普通的select语句（不加锁）。读取的是记录数据的可见版本，也可能是历史版本</p><p>​RC: 每次select，都生成一个快照读</p><p>​RR：开启事务后的第一个select语句才是快照读的地方。</p><p>readview中包含了四个核心字段：</p><p>​m_ids : 当前活跃事务ID集合</p><p>​min_trx_id: 最小活跃事务ID</p><p>​max_trx_id:最大事务ID+1</p><p>​creator_trx_id : ReadView创建者的事务ID</p><p>比较规则：</p><p><img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165740.png" alt="image-20251121144618843"></p><p><img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165817.png" alt="image-20251121144846958"><br><img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165839.png" alt="image-20251121144905975"></p><h2 id="并发事务控制方式二：锁"><a href="#并发事务控制方式二：锁" class="headerlink" title="并发事务控制方式二：锁"></a>并发事务控制方式二：锁</h2><p>除了MVCC，还有锁方案。锁可以看作是悲观控制的模式，多版本并发控制可以看作是乐观控制的模式。</p><p><strong>锁</strong> 控制方式下会通过锁来显式控制共享资源而不是通过调度手段，MySQL 中主要是通过 <strong>读写锁</strong> 来实现并发控制。</p><p><strong>共享锁（S 锁）</strong>：又称<strong>读锁</strong>，事务在<strong>读取记录</strong>的时候获取共享锁，允许多个事务同时获取（锁兼容）。</p><p><strong>排他锁（X 锁）</strong>：又称<strong>写锁</strong>&#x2F;独占锁，事务在<strong>修改记录</strong>的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条记录加任何类型的锁（锁不兼容）。</p><h2 id="表级锁与行级锁的区别？"><a href="#表级锁与行级锁的区别？" class="headerlink" title="表级锁与行级锁的区别？"></a>表级锁与行级锁的区别？</h2><ul><li><strong>表级锁：</strong> MySQL 中锁定粒度最大的一种锁（全局锁除外），是针对非索引字段加的锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。不过，触发锁冲突的概率最高，高并发下效率极低。表级锁和存储引擎无关，MyISAM 和 InnoDB 引擎都支持表级锁。</li><li><strong>行级锁：</strong> MySQL 中锁定粒度最小的一种锁，是 <strong>针对索引字段加的锁</strong> ，只针对当前操作的行记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。行级锁和存储引擎有关，是在存储引擎层面实现的。</li></ul><h2 id="行级锁使用的注意事项"><a href="#行级锁使用的注意事项" class="headerlink" title="行级锁使用的注意事项"></a>行级锁使用的注意事项</h2><p>InnoDB中行级锁针对索引字段加的锁，而表级锁针对非索引字段加的锁。当我们执行 <code>UPDATE</code>、<code>DELETE</code> 语句时，如果 <code>WHERE</code>条件中字段没有命中唯一索引或者索引失效的话，就会导致扫描全表对表中的所有行记录进行加锁。</p><h2 id="MySQL隔离级别基于锁实现吗？"><a href="#MySQL隔离级别基于锁实现吗？" class="headerlink" title="MySQL隔离级别基于锁实现吗？"></a>MySQL隔离级别基于锁实现吗？</h2><p>MySQL 的隔离级别基于锁和 MVCC 机制共同实现的。</p><p><strong>SERIALIZABLE 隔离级别是通过锁来实现的</strong>，<strong>READ-COMMITTED 和 REPEATABLE-READ 隔离级别是基于 MVCC 实现的</strong>。不过， SERIALIZABLE 之外的其他隔离级别可能也需要用到锁机制，就比如 REPEATABLE-READ 在当前读情况下需要使用加锁读来保证不会出现幻读。</p><h2 id="MySQL主从同步原理"><a href="#MySQL主从同步原理" class="headerlink" title="MySQL主从同步原理"></a>MySQL主从同步原理</h2><p>主从复制核心：二进制日志(BINLOG):记录了所有的DDL语句和DML语句，但不包括查询语句<img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251121165858.png" alt="image-20251121145358835"></p><ol><li>主库提交事务时会写入binlog</li><li>从库有一个IO线程专门读取binlog，并写入自己的Relay log</li><li>从库有一个SQL线程写自己的Relay log中记录的事件</li></ol><h2 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h2><ol><li>单表数据量很大（1000W &#x2F; 20G）</li><li>优化解决不了性能问题</li><li>IO瓶颈</li></ol><p>分库分表缓解了访问压力和存储压力</p><p>拆分方法： 垂直拆分，水平拆分</p><p>垂直分库：以表为依据，根据业务不同拆分到不同的库中。</p><p>垂直分表：以字段为依据，根据字段属性将不同字段拆分到不同表中。（不常用的字段单独放一个表&#x2F;大字段单独拆出来）</p><p>水平分库：将一个库的数据分到多个库中。</p><p>水平分表：将一个表中数据拆分到多个表中。（可以在一个库中）</p><p>水平分法：可以按照mod方式去拆分。但会产生其他的问题，如分布式事务一致性问题，跨节点关联查询等，解决办法：有一些中间件，如mycat等</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>从datasets到划分数据集</title>
      <link href="/2025/11/19/%E4%BB%8Edatasets%E5%88%B0%E5%88%92%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
      <url>/2025/11/19/%E4%BB%8Edatasets%E5%88%B0%E5%88%92%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<h1 id="dataset"><a href="#dataset" class="headerlink" title="dataset"></a>dataset</h1><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><p>​在PyTorch中，Dataset 类是<code>torch.utils.data</code>模块的一部分，它是一个<strong>抽象的基类</strong>，用于定义了数据集加载和处理的标准接口。通过继承这个类并实现其方法，可以创建自定义的数据集来适应各种机器学习任务。</p><h2 id="提供的函数接口"><a href="#提供的函数接口" class="headerlink" title="提供的函数接口"></a>提供的函数接口</h2><h3 id="getitem-方法"><a href="#getitem-方法" class="headerlink" title="__getitem__ 方法"></a><strong><code>__getitem__</code> 方法</strong></h3><p>​这是一个抽象方法，子类必须实现它。这个方法应该根据给定的索引返回对应的数据样本。如果子类没有实现这个方法，尝试获取数据样本时会抛出 <code>NotImplementedError</code>。</p><h3 id="getitems-方法"><a href="#getitems-方法" class="headerlink" title="__getitems__ 方法"></a><strong><code>__getitems__</code> 方法</strong></h3><p>​这个方法被注释掉了，但它是可选的，用于加速批量样本的加载。如果实现，它应该接受一个样本索引列表，并返回一个样本列表。</p><h3 id="add-方法"><a href="#add-方法" class="headerlink" title="__add__ 方法"></a><strong><code>__add__</code> 方法</strong></h3><p>​这个方法允许将两个 <code>Dataset</code> 对象相加，返回一个新的 <code>ConcatDataset</code> 对象，该对象将两个数据集合并为一个连续的数据集。</p><h3 id="len-方法"><a href="#len-方法" class="headerlink" title="__len__ 方法"></a><strong><code>__len__</code> 方法</strong></h3><p>​返回构建的数据集的长度信息。如果子类没有实现 <code>__len__</code> 方法，那么在尝试获取数据集大小时会抛出 <code>TypeError</code>，这是一种强制子类提供实现的方式。</p><h3 id="特别规定："><a href="#特别规定：" class="headerlink" title="特别规定："></a>特别规定：</h3><p>Dataset 类定义了以下两个核心方法，任何自定义数据集都需要实现这些方法：</p><ul><li><code>__len__(self)</code>：返回数据集中的样本总数。</li><li><code>__getitem__(self, idx)</code>：根据给定的索引idx返回一个样本。这个样本可以是一个数据点，也可以是一个数据点及其对应的标签。</li><li><code>_init_(self)</code>：初始化函数，一般要提供一个列表，列表中的元素是索引信息或者路径信息。</li></ul><h2 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">## Image用于读取图片</span></span><br><span class="line"><span class="comment">## jupyter环境下只要把对应的数据集放入对应的文件夹下即可</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyData</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,root_dir,label_dir</span>): <span class="comment">## 初始化类 root_dir是根路径，label_dir是标签</span></span><br><span class="line">        self.root_dir = root_dir <span class="comment">## 设置类中全局变量</span></span><br><span class="line">        self.label_dir = label_dir</span><br><span class="line">        self.path = os.path.join(self.root_dir,self.label_dir) <span class="comment">##得到完整的路径</span></span><br><span class="line">        <span class="comment">### os.listdir() 是 Python 标准库 os 模块中的一个函数，用于返回指定目录下的所有文件和子目录的名称列表。</span></span><br><span class="line">        self.img_path = os.listdir(self.path) <span class="comment">## 由完整路径得到图片名称索引列表</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>): <span class="comment">## 由图片索引读取图片</span></span><br><span class="line">        <span class="comment">## 读图片首先需要图片的地址</span></span><br><span class="line">        img_names = self.img_path[idx] <span class="comment">##从列表中选取idx对应的图片名，很重要的一点是：获取图片的路径也需要图片的名称</span></span><br><span class="line">        img_item_path = os.path.join(self.root_dir,self.label_dir,img_names) <span class="comment">##获得完整的图片路径</span></span><br><span class="line">        img= Image.<span class="built_in">open</span>(img_item_path) <span class="comment">##由图片的路径得到图片</span></span><br><span class="line">        label = self.label_dir</span><br><span class="line">        <span class="keyword">return</span> img,label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_path)</span><br><span class="line"></span><br><span class="line">root_dir = <span class="string">&quot;dataset/train&quot;</span></span><br><span class="line">ants_label_dir = <span class="string">&quot;ants_image&quot;</span></span><br><span class="line">bees_label_dir = <span class="string">&quot;bees_image&quot;</span></span><br><span class="line">ants_dataset = MyData(root_dir,ants_label_dir) <span class="comment">## 传入路径实例化一个类</span></span><br><span class="line">bees_dataset = MyData(root_dir,bees_label_dir)</span><br><span class="line"></span><br><span class="line">img,label = ants_dataset[<span class="number">0</span>]<span class="comment">## 通过传入下表来获取图片和对应的标签</span></span><br><span class="line">img.show()</span><br><span class="line"><span class="built_in">print</span>(label)</span><br><span class="line"></span><br><span class="line">train_dataset = ants_dataset + bees_dataset <span class="comment">##合并两个数据集</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(train_dataset)) <span class="comment">## 求长度</span></span><br></pre></td></tr></table></figure><p>其中__init__主要提供索引，最终提供一个<strong>列表</strong>，列表中是图片名称的索引，__getitem__主要完成由索引读取图片的过程函数，__len__用于得到列表的长度。<br><img src="https://cdn.jsdelivr.net/gh/whcComz1/picgoDemo/img/20251120104124.png" alt="格式.png"></p><p>根据给定的目录信息，构建对应的dataset。要求TC和FC在dataset中一一对应。</p><p>TC: data&#x2F;sub-HC001&#x2F;10min&#x2F;sub-HC001_Schaefer400_timeseries_partial-10min.csv</p><p>FC: data&#x2F;sub-HC001&#x2F;30min&#x2F;sub-HC001_Schaefer400_connectivity_partial-30min.csv</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Schaefer_Dataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    配对加载10分钟TC和30分钟FC的数据集</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_root, subject_ids=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化数据集</span></span><br><span class="line"><span class="string">        data_root: 数据根目录 (包含所有sub-*文件夹)</span></span><br><span class="line"><span class="string">        subject_ids: 可选，指定要加载的受试者ID列表</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.data_root = Path(data_root)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 收集所有符合条件的受试者</span></span><br><span class="line">        self.subjects = self._find_subjects(subject_ids)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.subjects:</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">&quot;未找到符合条件的受试者数据&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;成功初始化数据集: <span class="subst">&#123;<span class="built_in">len</span>(self.subjects)&#125;</span> 个受试者&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_find_subjects</span>(<span class="params">self, subject_ids</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;查找所有符合条件的受试者&quot;&quot;&quot;</span></span><br><span class="line">        subjects = []</span><br><span class="line">        <span class="comment"># 遍历所有sub-*文件夹</span></span><br><span class="line">        <span class="comment"># data_root.glob 从数据根目录（如 data/）中，找出所有以 sub- 开头的文件夹</span></span><br><span class="line">        <span class="comment"># subject_dir是以sub开头的，如sub-HC001</span></span><br><span class="line">        <span class="keyword">for</span> subject_dir <span class="keyword">in</span> self.data_root.glob(<span class="string">&#x27;sub-*&#x27;</span>):</span><br><span class="line">            <span class="comment"># .name：获取名称，得到string，.replace：将sub-替换成空字符,这样就从sub-HC001，得到了HC001</span></span><br><span class="line">            subject_id = subject_dir.name.replace(<span class="string">&#x27;sub-&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果指定了subject_ids，则过滤</span></span><br><span class="line">            <span class="keyword">if</span> subject_ids <span class="keyword">and</span> subject_id <span class="keyword">not</span> <span class="keyword">in</span> subject_ids:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 构建10min TC文件路径</span></span><br><span class="line">            <span class="comment"># / 是路径拼接运算符，作用类似字符串拼接，但更智能（会自动处理不同系统的路径分隔符，如 Windows 的 \ 和 Linux 的 /）。</span></span><br><span class="line">            <span class="comment"># f&quot;&#123;subject_dir.name&#125;_Schaefer400_timeseries_partial-10min.csv&quot;：是文件名，用 f-string 动态生成，由 3 部分组成</span></span><br><span class="line">            tc_file = subject_dir / <span class="string">&quot;10min&quot;</span> / <span class="string">f&quot;<span class="subst">&#123;subject_dir.name&#125;</span>_Schaefer400_timeseries_partial-10min.csv&quot;</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> tc_file.exists():</span><br><span class="line">                <span class="comment"># 尝试不带&quot;partial&quot;后缀的文件名</span></span><br><span class="line">                tc_file_alt = subject_dir / <span class="string">&quot;10min&quot;</span> / <span class="string">f&quot;<span class="subst">&#123;subject_dir.name&#125;</span>_Schaefer400_timeseries.csv&quot;</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> tc_file_alt.exists():</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;警告: 未找到受试者 <span class="subst">&#123;subject_id&#125;</span> 的10min TC数据&quot;</span>)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                tc_file = tc_file_alt</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 构建30min FC文件路径</span></span><br><span class="line">            fc_file = subject_dir / <span class="string">&quot;30min&quot;</span> / <span class="string">f&quot;<span class="subst">&#123;subject_dir.name&#125;</span>_Schaefer400_connectivity_partial-30min.csv&quot;</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> fc_file.exists():</span><br><span class="line">                <span class="comment"># 尝试不带&quot;partial&quot;后缀的文件名</span></span><br><span class="line">                fc_file_alt = subject_dir / <span class="string">&quot;30min&quot;</span> / <span class="string">f&quot;<span class="subst">&#123;subject_dir.name&#125;</span>_Schaefer400_connectivity.csv&quot;</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> fc_file_alt.exists():</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;警告: 未找到受试者 <span class="subst">&#123;subject_id&#125;</span> 的30min FC数据&quot;</span>)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                fc_file = fc_file_alt</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 提取标签</span></span><br><span class="line">            label = subject_id[:<span class="number">3</span>] <span class="keyword">if</span> <span class="built_in">len</span>(subject_id) &gt; <span class="number">3</span> <span class="keyword">else</span> subject_id</span><br><span class="line"></span><br><span class="line">            subjects.append(&#123;</span><br><span class="line">                <span class="string">&#x27;subject_id&#x27;</span>: subject_id,</span><br><span class="line">                <span class="string">&#x27;label&#x27;</span>: label,</span><br><span class="line">                <span class="string">&#x27;tc_path&#x27;</span>: tc_file,</span><br><span class="line">                <span class="string">&#x27;fc_path&#x27;</span>: fc_file</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> subjects</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.subjects)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;加载单个样本的配对数据&quot;&quot;&quot;</span></span><br><span class="line">        subject = self.subjects[idx]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 加载10分钟TC数据（预处理后的CSV）</span></span><br><span class="line">            tc_data = pd.read_csv(subject[<span class="string">&#x27;tc_path&#x27;</span>], header=<span class="literal">None</span>).values.astype(np.float32)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 确保正确的形状: (时间点, 脑区)</span></span><br><span class="line">            <span class="keyword">if</span> tc_data.shape[<span class="number">0</span>] == <span class="number">400</span>:  <span class="comment"># 如果是(脑区, 时间点)</span></span><br><span class="line">                tc_data = tc_data.T</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 加载30分钟FC数据</span></span><br><span class="line">            fc_data = pd.read_csv(subject[<span class="string">&#x27;fc_path&#x27;</span>], header=<span class="literal">None</span>).values.astype(np.float32)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 确保FC矩阵对称</span></span><br><span class="line">            <span class="keyword">if</span> fc_data.shape[<span class="number">0</span>] == <span class="number">400</span>:  <span class="comment"># 如果是(脑区, 脑区)</span></span><br><span class="line">                <span class="comment"># 确保是方阵</span></span><br><span class="line">                <span class="keyword">if</span> fc_data.shape[<span class="number">1</span>] != <span class="number">400</span>:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError(<span class="string">f&quot;FC矩阵形状不正确: <span class="subst">&#123;fc_data.shape&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="comment"># 对称化</span></span><br><span class="line">                fc_data = <span class="number">0.5</span> * (fc_data + fc_data.T)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">f&quot;FC矩阵形状不正确: <span class="subst">&#123;fc_data.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line">                <span class="string">&#x27;tc_data&#x27;</span>: torch.tensor(tc_data, dtype=torch.float32),</span><br><span class="line">                <span class="string">&#x27;fc_data&#x27;</span>: torch.tensor(fc_data, dtype=torch.float32),</span><br><span class="line">                <span class="string">&#x27;subject_id&#x27;</span>: subject[<span class="string">&#x27;subject_id&#x27;</span>],</span><br><span class="line">                <span class="string">&#x27;label&#x27;</span>: subject[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;加载文件出错: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;TC文件: <span class="subst">&#123;subject[<span class="string">&#x27;tc_path&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;FC文件: <span class="subst">&#123;subject[<span class="string">&#x27;fc_path&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">raise</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>__init__函数也是提供了索引列表，只是这里提供的是列表的列表。subject的每个元素也是一个列表，包含了dataset元素中所要有的subject_id，label，tc_file和fc_file。__getitem__函数主要通过构建的列表完成加载单个样本的配对数据。</p><h1 id="dataloader"><a href="#dataloader" class="headerlink" title="dataloader"></a>dataloader</h1><h2 id="1-接收数据集-dataset"><a href="#1-接收数据集-dataset" class="headerlink" title="1. 接收数据集(dataset)"></a>1. 接收数据集(dataset)</h2><p><code>DataLoader</code> 首先关联定义的 <code>Dataset</code> 实例，通过数据集的两个核心方法获取基础信息：</p><ul><li>调用 <code>dataset.__len__()</code> 知道总样本数（用于计算总批次）；</li><li>调用 <code>dataset.__getitem__(idx)</code> 按索引 <code>idx</code> 获取单个样本（如第 0 个样本的 TC&#x2F;FC 数据）。</li></ul><h2 id="2-确定批次参数"><a href="#2-确定批次参数" class="headerlink" title="2.确定批次参数"></a>2.确定批次参数</h2><p>根据传入的参数（<code>batch_size</code>、<code>shuffle</code> 等），<code>DataLoader</code> 规划如何提取样本：</p><ul><li><code>batch_size=4</code>：每批包含 4 个样本；</li><li><code>shuffle=True</code>（训练集）：每个 epoch 开始前，随机打乱所有样本的顺序，避免模型学习到样本顺序的规律；</li><li><code>shuffle=False</code>（验证 &#x2F; 测试集）：保持样本顺序不变，方便结果对齐。</li></ul><h2 id="3：多线程加载单个样本（可选）"><a href="#3：多线程加载单个样本（可选）" class="headerlink" title="3：多线程加载单个样本（可选）"></a>3：多线程加载单个样本（可选）</h2><p>如果设置了 <code>num_workers&gt;0</code>（如 <code>num_workers=2</code>），<code>DataLoader</code> 会启动多个子线程<strong>并行加载单个样本</strong>，加速数据读取：</p><ul><li>每个线程会调用 <code>dataset.__getitem__(idx)</code> 获取单个样本（如线程 1 加载 idx&#x3D;0，线程 2 加载 idx&#x3D;1）；</li><li>代码中 <code>num_workers=0</code>（默认），表示单线程加载（适合调试，多线程可能需注意 Windows 系统兼容性）。如果复制别人的代码在dataloader报错了，很可能是你的Windows环境不适合num_workers&gt;0的情况</li></ul><h2 id="4：用-collate-fn-组装批次数据"><a href="#4：用-collate-fn-组装批次数据" class="headerlink" title="4：用 collate_fn 组装批次数据"></a>4：用 <code>collate_fn</code> 组装批次数据</h2><p>这一步需要自定义了，不同的数据集collate_fn函数可能不一样。<code>collate_fn</code> 是 PyTorch <code>DataLoader</code> 中的一个<strong>自定义批量数据组装函数</strong>，用于将多个零散的单样本数据 “拼接” 成一个统一的批次数据（batch）。由于单个样本是字典（包含 <code>tc_data</code>、<code>fc_data</code> 等），<code>DataLoader</code> 需要用 <code>collate_fn</code> 将多个样本 “拼接” 成批次数据：def collate_fn(batch):中的batch含义：当 <code>batch_size=4</code> 时，<code>DataLoader</code> 会先收集 4 个这样的样本，组成一个列表 <code>batch = [样本1, 样本2, 样本3, 样本4]</code>。</p><h2 id="那为什么需要-collate-fn？"><a href="#那为什么需要-collate-fn？" class="headerlink" title="那为什么需要 collate_fn？"></a><strong>那为什么需要 collate_fn？</strong></h2><p>因为 <strong>每个 sample 是一个 dict</strong>，而且不同键对应的数据形状不一样，比如：</p><table><thead><tr><th>key</th><th>内容</th><th>格式</th><th>例子形状</th></tr></thead><tbody><tr><td><code>tc_data_10min</code></td><td>时间序列</td><td>Tensor</td><td>(250, 400)</td></tr><tr><td><code>fc_data_10min</code></td><td>功能连接矩阵</td><td>Tensor</td><td>(400, 400)</td></tr><tr><td><code>subject_id</code></td><td>被试编号</td><td>字符串</td><td>例如 <code>&#39;001&#39;</code></td></tr><tr><td><code>start</code> 或 <code>indices</code></td><td>数据增强信息</td><td>数字 或 array</td><td>长度可变</td></tr></tbody></table><p>要把多个样本合并成 batch —— 不同类型就需要<strong>不同的合并方式</strong>。</p><p>例如：</p><h3 id="✅-对-Tensor：要-torch-stack"><a href="#✅-对-Tensor：要-torch-stack" class="headerlink" title="✅ 对 Tensor：要 torch.stack"></a>✅ 对 Tensor：要 <code>torch.stack</code></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tc_batch = torch.stack([tc1, tc2, tc3, tc4])  # → (4, 250, 400)</span><br></pre></td></tr></table></figure><h3 id="✅-对数字：要做成一维-Tensor"><a href="#✅-对数字：要做成一维-Tensor" class="headerlink" title="✅ 对数字：要做成一维 Tensor"></a>✅ 对数字：要做成一维 Tensor</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start_batch = torch.tensor([10, 20, 30, 40])</span><br></pre></td></tr></table></figure><h3 id="✅-对字符串-ID：不能堆叠-→-保留成列表"><a href="#✅-对字符串-ID：不能堆叠-→-保留成列表" class="headerlink" title="✅ 对字符串 ID：不能堆叠 → 保留成列表"></a>✅ 对字符串 ID：不能堆叠 → 保留成列表</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">subject_ids = [&#x27;001&#x27;, &#x27;002&#x27;, &#x27;003&#x27;, &#x27;004&#x27;]</span><br></pre></td></tr></table></figure><p><strong>collate_fn 就是在定义：如何把这些单个样本合并成批次。</strong></p><hr><h2 id="如果没有自定义-collate-fn，会怎样？"><a href="#如果没有自定义-collate-fn，会怎样？" class="headerlink" title="如果没有自定义 collate_fn，会怎样？"></a><strong>如果没有自定义 collate_fn，会怎样？</strong></h2><p>PyTorch 默认会粗暴尝试 stack<br> 但如果 batch 中某个键不是 Tensor（比如 <code>subject_id</code> 是 string），就会 <strong>报错</strong>。</p><h2 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a><strong>一句话总结</strong></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">collate_fn 决定了 DataLoader 如何把「单个样本」合并成「一个 batch」。</span><br></pre></td></tr></table></figure><p>它的任务是：</p><table><thead><tr><th>类型</th><th>collate_fn 会做什么</th></tr></thead><tbody><tr><td>Tensor &#x2F; ndarray</td><td><code>torch.stack()</code> 变成 (batch, …)</td></tr><tr><td>数字</td><td>转为 tensor 一起合并</td></tr><tr><td>字符串、无法堆叠的数据</td><td>保留为列表，不报错</td></tr></tbody></table><hr><h2 id="为什么你一定需要自定义-collate-fn？"><a href="#为什么你一定需要自定义-collate-fn？" class="headerlink" title="为什么你一定需要自定义 collate_fn？"></a><strong>为什么你一定需要自定义 collate_fn？</strong></h2><p>因为你的 Dataset：</p><ul><li><strong>不同增强模式返回的字段不一样</strong></li><li><strong>样本字段包含 Tensor + 数字 + 字符串</strong></li><li><strong>如果不自定义会直接报错</strong></li></ul><p>自定义 collate_fn &#x3D; <strong>不改 Dataset 就能适配所有模式</strong> ✅</p><h2 id="5：返回批次数据并循环迭代"><a href="#5：返回批次数据并循环迭代" class="headerlink" title="5：返回批次数据并循环迭代"></a>5：返回批次数据并循环迭代</h2><p>用 <code>for batch in train_loader</code> 循环时，<code>DataLoader</code> 会按上述步骤不断生成批次数据，直到遍历完所有样本：</p><ul><li>每个 <code>batch</code> 是 <code>collate_fn</code> 返回的字典，包含批量的 <code>tc_data</code>、<code>fc_data</code> 等；</li><li>一个 epoch 结束后（所有样本都被加载过一次），如果 <code>shuffle=True</code>，会重新打乱样本顺序，开始下一个 epoch</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_paired_dataloader</span>(<span class="params">dataset, batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    创建用于配对TC和FC数据的DataLoader</span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">        dataset: Preprocess_Schaefer_Dataset实例</span></span><br><span class="line"><span class="string">        batch_size: 批次大小</span></span><br><span class="line"><span class="string">        shuffle: 是否打乱数据</span></span><br><span class="line"><span class="string">        num_workers: 数据加载线程数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;自定义批次组装函数&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 提取TC数据并堆叠</span></span><br><span class="line">        tc_data = torch.stack([item[<span class="string">&#x27;tc_data&#x27;</span>] <span class="keyword">for</span> item <span class="keyword">in</span> batch])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取FC数据并堆叠</span></span><br><span class="line">        fc_data = torch.stack([item[<span class="string">&#x27;fc_data&#x27;</span>] <span class="keyword">for</span> item <span class="keyword">in</span> batch])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取元数据</span></span><br><span class="line">        subject_ids = [item[<span class="string">&#x27;subject_id&#x27;</span>] <span class="keyword">for</span> item <span class="keyword">in</span> batch]</span><br><span class="line">        labels = [item[<span class="string">&#x27;label&#x27;</span>] <span class="keyword">for</span> item <span class="keyword">in</span> batch]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;tc_data&#x27;</span>: tc_data,  <span class="comment"># 形状: (batch, 时间点, 400)</span></span><br><span class="line">            <span class="string">&#x27;fc_data&#x27;</span>: fc_data,  <span class="comment"># 形状: (batch, 400, 400)</span></span><br><span class="line">            <span class="string">&#x27;subject_ids&#x27;</span>: subject_ids,</span><br><span class="line">            <span class="string">&#x27;labels&#x27;</span>: labels</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> DataLoader(</span><br><span class="line">        dataset,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        shuffle=shuffle,</span><br><span class="line">        collate_fn=collate_fn,</span><br><span class="line">        num_workers=num_workers,</span><br><span class="line">        pin_memory=<span class="literal">True</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="划分dataset"><a href="#划分dataset" class="headerlink" title="划分dataset"></a>划分dataset</h1><p>主要使用train_test_split函数。导入方法如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure><p><strong><code>train_test_split(\*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)</code></strong></p><p>参数说明：</p><p>*arrays: 单个数组或元组，表示需要划分的数据集。如果传入多个数组，则必须保证每个数组的第一维大小相同。</p><p>test_size: 测试集的大小（占总数据集的比例）。默认值为0.25，即将传入数据的25%作为测试集。</p><p>train_size: 训练集的大小（占总数据集的比例）。默认值为None，此时和test_size互补，即训练集的大小为(1-test_size)。</p><p>random_state: 随机数种子。可以设置一个整数，用于复现结果。默认为None。</p><p>shuffle: 是否随机打乱数据。默认为True。</p><p>stratify: 可选参数，用于进行分层抽样。传入标签数组，保证划分后的训练集和测试集中各类别样本比例与原始数据集相同。默认为None，即普通的随机划分。</p><p>返回值说明：</p><p>该函数返回一个元组(X_train, X_test, y_train, y_test)，其中X_train表示训练集的特征数据，X_test表示测试集的特征数据，y_train表示训练集的标签数据，y_test表示测试集的标签数据。</p><p> <strong>“先按规则划分 ID，再用划分好的 ID 去提取对应数据”</strong>，最终实现数据集的分类（训练集 &#x2F; 验证集 &#x2F; 测试集）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> data_set <span class="keyword">import</span> Schaefer_Dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_dataset</span>(<span class="params">dataset, test_size=<span class="number">0.2</span>, val_size=<span class="number">0.1</span>, random_state=<span class="number">42</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    划分训练集、验证集和测试集</span></span><br><span class="line"><span class="string">    确保每个标签组内按比例划分</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 获取所有受试者ID和标签</span></span><br><span class="line">    subject_ids = dataset.get_subject_ids()</span><br><span class="line">    labels = dataset.get_labels()</span><br><span class="line"><span class="comment"># 两步划分法</span></span><br><span class="line">    <span class="comment"># 先划分训练+验证 vs 测试</span></span><br><span class="line">    train_val_ids, test_ids, train_val_labels, _ = train_test_split(</span><br><span class="line">        subject_ids,</span><br><span class="line">        labels,</span><br><span class="line">        test_size=test_size,</span><br><span class="line">        stratify=labels,  <span class="comment"># 保持标签分布</span></span><br><span class="line">        random_state=random_state</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 再划分训练 vs 验证</span></span><br><span class="line">    train_ids, val_ids = train_test_split(</span><br><span class="line">        train_val_ids,</span><br><span class="line">        test_size=val_size / (<span class="number">1</span> - test_size),  <span class="comment"># 调整比例</span></span><br><span class="line">        stratify=train_val_labels,  <span class="comment"># 保持标签分布</span></span><br><span class="line">        random_state=random_state</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建子数据集</span></span><br><span class="line">    train_dataset = Schaefer_Dataset(dataset.data_root, subject_ids=train_ids)</span><br><span class="line">    val_dataset = Schaefer_Dataset(dataset.data_root, subject_ids=val_ids)</span><br><span class="line">    test_dataset = Schaefer_Dataset(dataset.data_root, subject_ids=test_ids)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;数据集划分结果:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  训练集: <span class="subst">&#123;<span class="built_in">len</span>(train_dataset)&#125;</span> 个样本&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  验证集: <span class="subst">&#123;<span class="built_in">len</span>(val_dataset)&#125;</span> 个样本&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  测试集: <span class="subst">&#123;<span class="built_in">len</span>(test_dataset)&#125;</span> 个样本&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_dataset, val_dataset, test_dataset</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>第一篇文章</title>
      <link href="/2025/09/19/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/"/>
      <url>/2025/09/19/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</url>
      
        <content type="html"><![CDATA[<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cout&lt;&lt;<span class="string">&quot; ni hao&quot;</span>&lt;&lt;endl;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>markdown常用指令</title>
      <link href="/2025/09/19/markdown%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"/>
      <url>/2025/09/19/markdown%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h3 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h3><h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><h2 id="二级标题用两个"><a href="#二级标题用两个" class="headerlink" title="二级标题用两个#"></a>二级标题用两个#</h2><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><h3 id="文字"><a href="#文字" class="headerlink" title="文字"></a>文字</h3><p>删除线用~~  <del>文字</del></p><p>斜体用* <em>文字</em>  <em>ctrl+ i</em></p><p>加粗用** <strong>文字</strong>  <strong>ctrl+ b</strong></p><p>斜体和加粗用三个*   <em><strong>文字</strong></em></p><p>下划线 ctrl+ u  <u>文字</u></p><p>高亮&#x3D;&#x3D;    &#x3D;&#x3D;文字&#x3D;&#x3D;</p><p>下标 用<del>包括  H</del>2<del>O</del>2~</p><p>上标 用^包括  m^2^</p><h3 id="表情"><a href="#表情" class="headerlink" title="表情"></a>表情</h3><p>:+缩写   :smile:   :100:  </p><h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><p>使用’|’ 来分割不同单元格,使用’-‘来分割表头和其他行</p><p>建议记住快捷键ctrl + t</p><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p>使用&gt; 加话</p><blockquote><p>“123”</p></blockquote><p>嵌套引用 &gt; &gt;&gt; &gt;&gt;&gt;</p><blockquote><p>“12345”</p><blockquote><p>“5678”</p></blockquote></blockquote><h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><h4 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h4><p>使用*&#x2F;+&#x2F;-</p><ul><li>1</li><li>2</li><li>3</li></ul><h4 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h4><p>以数字和. 和空格开始</p><ol><li>a</li><li>b</li></ol><h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><p>三个&#96; 加语言名称</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cout&lt;&lt;<span class="string">&quot;helloworld&quot;</span>&lt;&lt;endl</span><br></pre></td></tr></table></figure><h3 id="行内代码"><a href="#行内代码" class="headerlink" title="行内代码"></a>行内代码</h3><p><code>JAVA</code>  用一个&#96;包括</p><h3 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h3><p>三个*加空格</p><hr><h3 id="跳转"><a href="#跳转" class="headerlink" title="跳转"></a>跳转</h3><hr><h4 id="外部"><a href="#外部" class="headerlink" title="外部"></a>外部</h4><p>[提示文字]（link） ctrl+点击</p><p><a href="https://whccomz1.github.io/whcc.github.io/">我的blog</a>  </p><h4 id="自动链接"><a href="#自动链接" class="headerlink" title="自动链接"></a>自动链接</h4><p>使用&lt;&gt;包括URL和邮箱 ，自动生产超链接</p><p>&lt; <a href="https://whccomz1.github.io/whcc.github.io/%3E">https://whccomz1.github.io/whcc.github.io/&gt;</a> </p><p>图片</p><p><img src="/%E5%9B%BE%E7%89%87%E8%B7%AF%E5%BE%84" alt="自己起的名字"></p><p><img src="https://tse1.mm.bing.net/th/id/OIP.IJZgTNx1vp9EML_1wV5p2gHaEo?r=0&rs=1&pid=ImgDetMain&o=7&rm=3" alt="网上的图片"> </p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
